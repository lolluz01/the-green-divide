{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2becc9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from Eurostat...\n",
      "Data saved to ../data/raw/nrg_ind_ren_linear.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Eurostat API endpoint for 'nrg_ind_ren' dataset\n",
    "DATA_URL = \"https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/nrg_ind_ren?format=SDMX-CSV&compressed=false\"\n",
    "OUTPUT_FILE = \"../data/raw/nrg_ind_ren_linear.csv\"\n",
    "\n",
    "print(f\"Fetching data from Eurostat...\")\n",
    "\n",
    "try:\n",
    "    response = requests.get(DATA_URL)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with open(OUTPUT_FILE, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    print(f\"Data saved to {OUTPUT_FILE}\")\n",
    "\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Download failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2216eb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cleaned. Shape: (773, 5)\n",
      "  nrg_bal geo  TIME_PERIOD  OBS_VALUE           Settore\n",
      "0     REN  AL         2004     29.620  Totale (Overall)\n",
      "1     REN  AL         2005     31.367  Totale (Overall)\n",
      "2     REN  AL         2006     32.070  Totale (Overall)\n",
      "3     REN  AL         2007     32.657  Totale (Overall)\n",
      "4     REN  AL         2008     32.448  Totale (Overall)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load raw Eurostat data\n",
    "df = pd.read_csv('../data/raw/nrg_ind_ren_linear.csv')\n",
    "\n",
    "# Configuration: Map technical codes to readable labels (Italian for viz)\n",
    "SECTOR_MAP = {\n",
    "    'REN': 'Totale (Overall)',\n",
    "    'REN_E': 'Elettricità',\n",
    "    'REN_T': 'Trasporti',\n",
    "    'REN_HC': 'Riscaldamento & Raffreddamento'\n",
    "}\n",
    "\n",
    "# Select relevant columns and drop missing values\n",
    "cols = ['nrg_bal', 'geo', 'TIME_PERIOD', 'OBS_VALUE']\n",
    "df = df[cols].dropna(subset=['OBS_VALUE'])\n",
    "\n",
    "# Filter rows based on our sector interest and map labels\n",
    "df = df[df['nrg_bal'].isin(SECTOR_MAP.keys())].copy()\n",
    "df['Settore'] = df['nrg_bal'].map(SECTOR_MAP)\n",
    "\n",
    "print(f\"Dataset cleaned. Shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e55559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../data/raw/sdg_out_000016340_i23_en.csv...\n",
      "Done. Exported to ../data/output/dati_unece_iso_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Source: https://w3.unece.org/SDG/en/Indicator?id=23\n",
    "# Note: Download csv manually to this folder\n",
    "INPUT_FILE = '../data/raw/sdg_out_000016340_i23_en.csv'\n",
    "OUTPUT_FILE = '../data/output/dati_unece_iso_clean.csv'\n",
    "\n",
    "COUNTRY_TO_ISO = {\n",
    "    'Albania': 'AL', 'Andorra': 'AD', 'Armenia': 'AM', 'Austria': 'AT', \n",
    "    'Azerbaijan': 'AZ', 'Belarus': 'BY', 'Belgium': 'BE', \n",
    "    'Bosnia and Herzegovina': 'BA', 'Bulgaria': 'BG', 'Croatia': 'HR', \n",
    "    'Cyprus': 'CY', 'Czechia': 'CZ', 'Denmark': 'DK', 'Estonia': 'EE', \n",
    "    'Finland': 'FI', 'France': 'FR', 'Georgia': 'GE', 'Germany': 'DE', \n",
    "    'Greece': 'GR', 'Hungary': 'HU', 'Iceland': 'IS', 'Ireland': 'IE', \n",
    "    'Israel': 'IL', 'Italy': 'IT', 'Kazakhstan': 'KZ', 'Kyrgyzstan': 'KG', \n",
    "    'Latvia': 'LV', 'Liechtenstein': 'LI', 'Lithuania': 'LT', \n",
    "    'Luxembourg': 'LU', 'Malta': 'MT', 'Montenegro': 'ME', \n",
    "    'Netherlands': 'NL', 'North Macedonia': 'MK', 'Norway': 'NO', \n",
    "    'Poland': 'PL', 'Portugal': 'PT', 'Republic of Moldova': 'MD', 'Moldova': 'MD',\n",
    "    'Romania': 'RO', 'Russian Federation': 'RU', 'Serbia': 'RS', \n",
    "    'Slovakia': 'SK', 'Slovenia': 'SI', 'Spain': 'ES', 'Sweden': 'SE', \n",
    "    'Switzerland': 'CH', 'Tajikistan': 'TJ', 'Türkiye': 'TR', 'Turkey': 'TR',\n",
    "    'Turkmenistan': 'TM', 'Ukraine': 'UA', 'United Kingdom': 'GB', \n",
    "    'Uzbekistan': 'UZ', 'United States': 'US', 'Canada': 'CA'\n",
    "}\n",
    "\n",
    "BLACKLIST = ['US', 'CA', 'UZ', 'TM', 'TJ', 'KG', 'KZ', 'IL', 'AM', 'AZ', 'GE']\n",
    "\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    print(f\"Error: File '{INPUT_FILE}' not found.\")\n",
    "    print(\"Please download it from https://w3.unece.org/SDG/en/Indicator?id=23\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"Reading {INPUT_FILE}...\")\n",
    "\n",
    "# 1. Load Data\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE, header=1, encoding='latin1')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(INPUT_FILE, header=1, encoding='cp1252')\n",
    "\n",
    "# 2. Pre-processing\n",
    "df.columns = df.columns.str.strip()\n",
    "df['Period'] = pd.to_numeric(df['Period'], errors='coerce')\n",
    "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "\n",
    "# 3. Filter: Most recent year per country\n",
    "df = df.sort_values(['Country_E', 'Period'], ascending=[True, False])\n",
    "df = df.drop_duplicates(subset=['Country_E'], keep='first').copy()\n",
    "\n",
    "# 4. Map ISO codes and filter blacklist\n",
    "df['iso_code'] = df['Country_E'].map(COUNTRY_TO_ISO)\n",
    "df = df[df['iso_code'].notna()]\n",
    "df = df[~df['iso_code'].isin(BLACKLIST)]\n",
    "\n",
    "# 5. Export\n",
    "df[['iso_code', 'Value']].to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(f\"Done. Exported to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de34de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset from Our World in Data...\n",
      "Done. File saved to: ../data/output/italy_energy_mix_1990-2023.csv\n",
      "Range: 1990 - 2025\n",
      "Shape: (36, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Source: Our World in Data (OWID)\n",
    "DATA_URL = \"https://raw.githubusercontent.com/owid/energy-data/master/owid-energy-data.csv\"\n",
    "OUTPUT_FILE = \"../data/output/italy_energy_mix_1990-2023.csv\"\n",
    "START_YEAR = 1990\n",
    "\n",
    "# Map OWID columns to display labels\n",
    "COLUMN_MAPPING = {\n",
    "    'year': 'Year',\n",
    "    'coal_electricity': 'Coal',\n",
    "    'gas_electricity': 'Gas',\n",
    "    'oil_electricity': 'Oil',\n",
    "    'hydro_electricity': 'Hydro',\n",
    "    'solar_electricity': 'Solar',\n",
    "    'wind_electricity': 'Wind',\n",
    "    'biofuel_electricity': 'Bioenergy',\n",
    "    'nuclear_electricity': 'Nuclear',\n",
    "    'other_renewable_electricity': 'Other Renewables'\n",
    "}\n",
    "\n",
    "def generate_energy_mix_csv():\n",
    "    print(\"Downloading dataset from Our World in Data...\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(DATA_URL)\n",
    "        \n",
    "        # Filter: Country and Time Range\n",
    "        df = df[(df['country'] == 'Italy') & (df['year'] >= START_YEAR)].copy()\n",
    "        \n",
    "        # Select relevant columns that exist in the dataset\n",
    "        available_cols = [c for c in COLUMN_MAPPING.keys() if c in df.columns]\n",
    "        df = df[available_cols].rename(columns=COLUMN_MAPPING)\n",
    "        \n",
    "        # Data Cleaning: Fill NaN with 0 for cleaner stack charts\n",
    "        df = df.fillna(0)\n",
    "        \n",
    "        # Sort chronologically\n",
    "        df = df.sort_values(by='Year')\n",
    "        \n",
    "        # Export\n",
    "        df.to_csv(OUTPUT_FILE, index=False)\n",
    "        \n",
    "        print(f\"Done. File saved to: {OUTPUT_FILE}\")\n",
    "        print(f\"Range: {df['Year'].min()} - {df['Year'].max()}\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_energy_mix_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95952efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from Eurostat...\n",
      "Download successful. File saved: ../data/raw/nrg_ind_ren_FULL.gz\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Eurostat full dataset endpoint (compressed TSV format)\n",
    "URL = \"https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/nrg_ind_ren?format=TSV&compressed=true\"\n",
    "OUTPUT_FILE = \"../data/raw/nrg_ind_ren_FULL.gz\"\n",
    "\n",
    "print(f\"Starting download from Eurostat...\")\n",
    "\n",
    "try:\n",
    "    # Set timeout to handle potential server lags\n",
    "    response = requests.get(URL, timeout=120)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with open(OUTPUT_FILE, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        \n",
    "    print(f\"Download successful. File saved: {OUTPUT_FILE}\")\n",
    "\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Error during download: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d9e448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../data/raw/nrg_ind_ren_FULL.gz...\n",
      "Success. Data exported to ../data/output/eurostat_sector_gap_flourish.csv\n",
      "Years covered: 2004 - 2024\n",
      "nrg_bal  Year  Electricity  Heating & Cooling  Transport\n",
      "0        2004       15.871             11.735      1.432\n",
      "1        2005       16.402             12.437      1.819\n",
      "2        2006       16.879             13.210      2.472\n",
      "3        2007       17.647             14.819      2.887\n",
      "4        2008       18.526             15.325      4.133\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configuration\n",
    "INPUT_FILES = ['../data/raw/nrg_ind_ren_FULL.gz', '../data/raw/nrg_ind_ren.gz']\n",
    "OUTPUT_FILE = '../data/output/eurostat_sector_gap_flourish.csv'\n",
    "TARGET_GEO = 'EU27_2020'  # Fallback to similar code if not found\n",
    "\n",
    "# Eurostat codes to readable English labels\n",
    "SECTOR_MAP = {\n",
    "    'REN_ELC': 'Electricity',\n",
    "    'REN_TRA': 'Transport', \n",
    "    'REN_HEAT_CL': 'Heating & Cooling'\n",
    "}\n",
    "\n",
    "def get_input_file():\n",
    "    \"\"\"Finds the first available input file from the list.\"\"\"\n",
    "    for f in INPUT_FILES:\n",
    "        if os.path.exists(f):\n",
    "            return f\n",
    "    return None\n",
    "\n",
    "def process_eurostat_data():\n",
    "    input_path = get_input_file()\n",
    "    \n",
    "    if not input_path:\n",
    "        print(f\"Error: Input file not found. Checked: {INPUT_FILES}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"Processing {input_path}...\")\n",
    "\n",
    "    try:\n",
    "        # 1. Load compressed TSV\n",
    "        # Eurostat TSVs often have a complex first column containing multiple keys\n",
    "        with gzip.open(input_path, 'rt') as f:\n",
    "            df = pd.read_csv(f, sep='\\t', dtype=str)\n",
    "\n",
    "        # 2. Parse the composite index column (freq,nrg_bal,unit,geo\\TIME_PERIOD)\n",
    "        # Example format: \"A,REN,kTOE,AT\\2022\"\n",
    "        first_col = df.columns[0]\n",
    "        meta_data = df[first_col].str.split(',', expand=True)\n",
    "        \n",
    "        # Assign proper columns\n",
    "        df['nrg_bal'] = meta_data[1]\n",
    "        df['geo'] = meta_data[3].str.split(r'\\\\').str[0].str.strip()\n",
    "        \n",
    "        # Drop the complex index after extraction\n",
    "        df.drop(columns=[first_col], inplace=True)\n",
    "\n",
    "        # 3. Filter by Geography (EU27)\n",
    "        if TARGET_GEO not in df['geo'].unique():\n",
    "            # Fallback: look for any EU27 code if the specific version changed\n",
    "            alternatives = [g for g in df['geo'].unique() if 'EU27' in str(g)]\n",
    "            geo_filter = alternatives[0] if alternatives else TARGET_GEO\n",
    "            print(f\"Notice: '{TARGET_GEO}' not found. Using '{geo_filter}' instead.\")\n",
    "        else:\n",
    "            geo_filter = TARGET_GEO\n",
    "            \n",
    "        df = df[df['geo'] == geo_filter].copy()\n",
    "\n",
    "        # 4. Filter by Sector\n",
    "        df = df[df['nrg_bal'].isin(SECTOR_MAP.keys())]\n",
    "\n",
    "        if df.empty:\n",
    "            print(\"Warning: No matching sectors found. Check if dataset is aggregated (REN only).\")\n",
    "            return\n",
    "\n",
    "        # 5. Reshape (Melt) - Convert Years from columns to rows\n",
    "        # Identify year columns (everything that is not metadata)\n",
    "        id_vars = ['nrg_bal', 'geo']\n",
    "        value_vars = [c for c in df.columns if c not in id_vars and 'freq' not in c and 'unit' not in c]\n",
    "        \n",
    "        df_melted = df.melt(\n",
    "            id_vars=['nrg_bal'],\n",
    "            value_vars=value_vars,\n",
    "            var_name='Year',\n",
    "            value_name='Value'\n",
    "        )\n",
    "\n",
    "        # 6. Clean Values\n",
    "        # Remove flags (e.g. \"12.5 p\" -> \"12.5\") and handle non-numeric\n",
    "        df_melted['Value'] = df_melted['Value'].astype(str).str.split().str[0]\n",
    "        df_melted['Value'] = pd.to_numeric(df_melted['Value'], errors='coerce')\n",
    "        \n",
    "        # Clean Year and ensure integer type\n",
    "        df_melted['Year'] = df_melted['Year'].str.strip()\n",
    "        df_melted = df_melted[df_melted['Year'].str.match(r'^\\d{4}$', na=False)]\n",
    "        df_melted['Year'] = df_melted['Year'].astype(int)\n",
    "\n",
    "        # Remove rows with no data\n",
    "        df_melted = df_melted.dropna(subset=['Value'])\n",
    "\n",
    "        # 7. Pivot for Final Output (Year x Sectors)\n",
    "        df_pivot = df_melted.pivot_table(\n",
    "            index='Year',\n",
    "            columns='nrg_bal',\n",
    "            values='Value',\n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "\n",
    "        # Rename columns to English\n",
    "        df_pivot.rename(columns=SECTOR_MAP, inplace=True)\n",
    "        df_pivot = df_pivot.sort_values('Year')\n",
    "\n",
    "        # 8. Export\n",
    "        df_pivot.to_csv(OUTPUT_FILE, index=False)\n",
    "        \n",
    "        print(f\"Success. Data exported to {OUTPUT_FILE}\")\n",
    "        print(f\"Years covered: {df_pivot['Year'].min()} - {df_pivot['Year'].max()}\")\n",
    "        print(df_pivot.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Critical error during processing: {e}\")\n",
    "        # In production, we might log the traceback here\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_eurostat_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a09f324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing regional trends from ../data/raw/nrg_ind_ren_FULL.gz...\n",
      "Success. Regional trends exported to ../data/output/eurostat_regional_trends.csv\n",
      "Region  Year  Eastern Europe  Nordics  Southern Europe  Western Europe\n",
      "16      2020       23.485667  59.3654        22.615750       18.514571\n",
      "17      2021       23.961889  60.2992        22.926000       17.732571\n",
      "18      2022       24.734667  62.1824        23.070750       18.805857\n",
      "19      2023       26.038889  63.4156        24.173375       21.055714\n",
      "20      2024       27.233333  63.7390        24.531000       21.996571\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configuration\n",
    "INPUT_FILES = ['../data/raw/nrg_ind_ren_FULL.gz', '../data/raw/nrg_ind_ren.gz']\n",
    "OUTPUT_FILE = '../data/output/eurostat_regional_trends.csv'\n",
    "\n",
    "# Regional Grouping (Excluded UK and CH as requested)\n",
    "REGIONS = {\n",
    "    'Nordics': ['SE', 'FI', 'DK', 'NO', 'IS'], \n",
    "    'Western Europe': ['DE', 'FR', 'BE', 'NL', 'LU', 'AT', 'IE'],\n",
    "    'Southern Europe': ['IT', 'ES', 'PT', 'EL', 'MT', 'CY', 'HR', 'SI'],\n",
    "    'Eastern Europe': ['PL', 'CZ', 'HU', 'SK', 'RO', 'BG', 'EE', 'LV', 'LT']\n",
    "}\n",
    "\n",
    "def get_input_file():\n",
    "    for f in INPUT_FILES:\n",
    "        if os.path.exists(f):\n",
    "            return f\n",
    "    return None\n",
    "\n",
    "def process_regional_trends():\n",
    "    input_path = get_input_file()\n",
    "    \n",
    "    if not input_path:\n",
    "        print(f\"Error: Input file not found. Checked: {INPUT_FILES}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"Processing regional trends from {input_path}...\")\n",
    "\n",
    "    try:\n",
    "        # 1. Load Data\n",
    "        with gzip.open(input_path, 'rt') as f:\n",
    "            df = pd.read_csv(f, sep='\\t', dtype=str)\n",
    "\n",
    "        # 2. Parse Metadata (Split first column)\n",
    "        first_col = df.columns[0]\n",
    "        meta = df[first_col].str.split(',', expand=True)\n",
    "        \n",
    "        df['nrg_bal'] = meta[1]\n",
    "        df['geo'] = meta[3].str.split(r'\\\\').str[0].str.strip()\n",
    "        df.drop(columns=[first_col], inplace=True)\n",
    "\n",
    "        # 3. Create Country -> Region Map\n",
    "        # Flatten the dictionary for easy mapping\n",
    "        country_to_region = {code: region for region, codes in REGIONS.items() for code in codes}\n",
    "        \n",
    "        # 4. Filter Data\n",
    "        # Keep only 'REN' (Overall Share) and countries in our regions\n",
    "        mask = (df['nrg_bal'] == 'REN') & (df['geo'].isin(country_to_region.keys()))\n",
    "        df = df[mask].copy()\n",
    "        \n",
    "        # Assign Region column\n",
    "        df['Region'] = df['geo'].map(country_to_region)\n",
    "\n",
    "        # 5. Melt (Wide to Long)\n",
    "        # Identify year columns (digits only)\n",
    "        id_vars = ['geo', 'Region', 'nrg_bal']\n",
    "        value_vars = [c for c in df.columns if c not in id_vars and c.strip().isdigit()]\n",
    "        \n",
    "        df_melted = df.melt(\n",
    "            id_vars=id_vars,\n",
    "            value_vars=value_vars,\n",
    "            var_name='Year',\n",
    "            value_name='Value'\n",
    "        )\n",
    "\n",
    "        # 6. Clean Numeric Values\n",
    "        # Handle Eurostat flags (e.g. \"15.4 e\") -> take first part, convert to float\n",
    "        df_melted['Value'] = df_melted['Value'].astype(str).str.split().str[0]\n",
    "        df_melted['Value'] = pd.to_numeric(df_melted['Value'], errors='coerce')\n",
    "        \n",
    "        # Clean Year\n",
    "        df_melted['Year'] = df_melted['Year'].astype(int)\n",
    "        \n",
    "        # Drop missing values\n",
    "        df_melted = df_melted.dropna(subset=['Value'])\n",
    "\n",
    "        # 7. Aggregate (Mean per Region per Year)\n",
    "        df_trends = df_melted.groupby(['Year', 'Region'])['Value'].mean().reset_index()\n",
    "\n",
    "        # 8. Pivot (Year x Regions) for visualization tools\n",
    "        df_final = df_trends.pivot(index='Year', columns='Region', values='Value').reset_index()\n",
    "        df_final = df_final.sort_values('Year')\n",
    "\n",
    "        # Export\n",
    "        df_final.to_csv(OUTPUT_FILE, index=False)\n",
    "        \n",
    "        print(f\"Success. Regional trends exported to {OUTPUT_FILE}\")\n",
    "        print(df_final.tail())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_regional_trends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32efc67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ../data/raw/nrg_ind_ren_FULL.gz...\n",
      "Parsing ../data/raw/nrg_ind_id.tsv.gz...\n",
      "Filtering data for year 2022...\n",
      "Merging datasets...\n",
      "Success. Data exported to ../data/output/war_impact_scatter.csv\n",
      "   geo  Year_x  Renewables_Share          nrg_bal  Year_y  Import_Dependency  \\\n",
      "13  AT    2022            34.057  C0000X0350-0370    2022             99.905   \n",
      "14  AT    2022            34.057            C0110    2022            125.010   \n",
      "15  AT    2022            34.057            C0121    2022             98.084   \n",
      "16  AT    2022            34.057            C0129    2022            101.695   \n",
      "17  AT    2022            34.057            C0210    2022            100.000   \n",
      "\n",
      "            Region  \n",
      "13  Western Europe  \n",
      "14  Western Europe  \n",
      "15  Western Europe  \n",
      "16  Western Europe  \n",
      "17  Western Europe  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "\n",
    "# Configuration\n",
    "REN_FILES = ['../data/raw/nrg_ind_ren_FULL.gz', '../data/raw/nrg_ind_ren.gz']\n",
    "DEP_FILE = '../data/raw/nrg_ind_id.tsv.gz'\n",
    "\n",
    "# UPDATED URL: Using the SDMX API endpoint instead of the static file path (More robust)\n",
    "DEP_URL = \"https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/nrg_ind_id?format=TSV&compressed=true\"\n",
    "\n",
    "OUTPUT_FILE = '../data/output/war_impact_scatter.csv'\n",
    "TARGET_YEAR = 2022\n",
    "\n",
    "# Region Mapping\n",
    "REGIONS = {\n",
    "    'Nordics': ['SE', 'FI', 'DK', 'NO', 'IS'], \n",
    "    'Western Europe': ['DE', 'FR', 'BE', 'NL', 'LU', 'AT', 'IE', 'CH'],\n",
    "    'Southern Europe': ['IT', 'ES', 'PT', 'EL', 'MT', 'CY', 'HR', 'SI'],\n",
    "    'Eastern Europe': ['PL', 'CZ', 'HU', 'SK', 'RO', 'BG', 'EE', 'LV', 'LT']\n",
    "}\n",
    "\n",
    "def get_renewable_file():\n",
    "    for f in REN_FILES:\n",
    "        if os.path.exists(f):\n",
    "            return f\n",
    "    return None\n",
    "\n",
    "def download_dependency_file():\n",
    "    \"\"\"Downloads the dependency dataset using the robust API endpoint.\"\"\"\n",
    "    print(f\"Downloading data from Eurostat API to {DEP_FILE}...\")\n",
    "    try:\n",
    "        # Increase timeout because API generation can take a few seconds\n",
    "        r = requests.get(DEP_URL, stream=True, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        \n",
    "        with open(DEP_FILE, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(\"Download complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download failed: {e}\")\n",
    "        # Stop execution cleanly\n",
    "        sys.exit(1)\n",
    "\n",
    "def parse_eurostat_tsv(filepath, value_name):\n",
    "    \"\"\"\n",
    "    Generic parser for Eurostat TSV.GZ files.\n",
    "    \"\"\"\n",
    "    print(f\"Parsing {filepath}...\")\n",
    "    try:\n",
    "        with gzip.open(filepath, 'rt') as f:\n",
    "            df = pd.read_csv(f, sep='\\t', dtype=str)\n",
    "    except EOFError:\n",
    "        print(f\"Error: The file {filepath} seems corrupted. Delete it and run again.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 1. Parse Metadata\n",
    "    first_col = df.columns[0]\n",
    "    meta = df[first_col].str.split(',', expand=True)\n",
    "    \n",
    "    # Extract Geo (usually the last element in the comma-separated key)\n",
    "    df['geo'] = meta.iloc[:, -1].str.split(r'\\\\').str[0].str.strip()\n",
    "    \n",
    "    # Keep nrg_bal if available\n",
    "    if meta.shape[1] > 2:\n",
    "        df['nrg_bal'] = meta[1]\n",
    "\n",
    "    df.drop(columns=[first_col], inplace=True)\n",
    "\n",
    "    # 2. Melt\n",
    "    id_vars = ['geo', 'nrg_bal'] if 'nrg_bal' in df.columns else ['geo']\n",
    "    value_vars = [c for c in df.columns if c.strip().isdigit()]\n",
    "    \n",
    "    df_melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='Year', value_name=value_name)\n",
    "\n",
    "    # 3. Clean Numeric Data\n",
    "    df_melted[value_name] = df_melted[value_name].astype(str).str.split().str[0]\n",
    "    df_melted[value_name] = pd.to_numeric(df_melted[value_name], errors='coerce')\n",
    "    \n",
    "    # 4. Clean Year\n",
    "    df_melted['Year'] = df_melted['Year'].astype(int)\n",
    "    \n",
    "    return df_melted.dropna(subset=[value_name])\n",
    "\n",
    "def process_war_impact():\n",
    "    # 1. Check/Load Renewables\n",
    "    ren_file = get_renewable_file()\n",
    "    if not ren_file:\n",
    "        print(\"Error: Renewables file not found (nrg_ind_ren_FULL.gz). Run previous scripts first.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    df_ren = parse_eurostat_tsv(ren_file, 'Renewables_Share')\n",
    "    # Filter for 'REN' (Overall share)\n",
    "    df_ren = df_ren[df_ren['nrg_bal'] == 'REN'].drop(columns=['nrg_bal'])\n",
    "\n",
    "    # 2. Check/Download Dependency Data\n",
    "    if not os.path.exists(DEP_FILE):\n",
    "        download_dependency_file()\n",
    "    \n",
    "    df_dep = parse_eurostat_tsv(DEP_FILE, 'Import_Dependency')\n",
    "    \n",
    "    # 3. Filter Target Year\n",
    "    print(f\"Filtering data for year {TARGET_YEAR}...\")\n",
    "    \n",
    "    # Check if 2022 exists, otherwise fallback to max year\n",
    "    max_year_ren = df_ren['Year'].max()\n",
    "    max_year_dep = df_dep['Year'].max()\n",
    "    \n",
    "    if TARGET_YEAR not in df_ren['Year'].unique():\n",
    "        print(f\"Warning: Year {TARGET_YEAR} not in Renewables. Using {max_year_ren}\")\n",
    "        df_ren_2022 = df_ren[df_ren['Year'] == max_year_ren]\n",
    "    else:\n",
    "        df_ren_2022 = df_ren[df_ren['Year'] == TARGET_YEAR]\n",
    "\n",
    "    if TARGET_YEAR not in df_dep['Year'].unique():\n",
    "        print(f\"Warning: Year {TARGET_YEAR} not in Dependency. Using {max_year_dep}\")\n",
    "        df_dep_2022 = df_dep[df_dep['Year'] == max_year_dep]\n",
    "    else:\n",
    "        df_dep_2022 = df_dep[df_dep['Year'] == TARGET_YEAR]\n",
    "\n",
    "    # 4. Merge\n",
    "    print(\"Merging datasets...\")\n",
    "    df_final = pd.merge(df_ren_2022, df_dep_2022, on='geo', how='inner')\n",
    "\n",
    "    # 5. Map Regions\n",
    "    country_to_region = {code: region for region, codes in REGIONS.items() for code in codes}\n",
    "    df_final['Region'] = df_final['geo'].map(country_to_region)\n",
    "    \n",
    "    # Remove unmapped countries\n",
    "    df_final = df_final.dropna(subset=['Region'])\n",
    "\n",
    "    # 6. Export\n",
    "    final_cols = ['geo', 'Region', 'Renewables_Share', 'Import_Dependency']\n",
    "    df_final[final_cols].to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "    print(f\"Success. Data exported to {OUTPUT_FILE}\")\n",
    "    print(df_final.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_war_impact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9698a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing renewable growth (2012-2022) from ../data/raw/nrg_ind_ren_FULL.gz...\n",
      "Success. Comparison data exported to ../data/output/race_to_zero_growth.csv\n",
      "Year Country_Name  Value_2012  Value_2022  Growth_Points\n",
      "11         Sweden      49.403      66.287         16.884\n",
      "2         Denmark      25.465      41.368         15.903\n",
      "5         Finland      34.222      47.740         13.518\n",
      "8     Netherlands       4.659      15.291         10.632\n",
      "3           Spain      14.239      21.837          7.598\n",
      "1         Germany      13.549      20.829          7.280\n",
      "6          France      13.239      20.330          7.091\n",
      "4      EU Average      16.002      23.003          7.001\n",
      "0         Belgium       7.086      13.831          6.745\n",
      "9          Poland      10.955      16.644          5.689\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configuration\n",
    "INPUT_FILES = ['../data/raw/nrg_ind_ren_FULL.gz', '../data/raw/nrg_ind_ren.gz']\n",
    "OUTPUT_FILE = '../data/output/race_to_zero_growth.csv'\n",
    "START_YEAR = 2012\n",
    "END_YEAR = 2022\n",
    "\n",
    "# Analysis Scope: A representative mix of EU economies\n",
    "SELECTED_COUNTRIES = [\n",
    "    'EU27_2020', 'SE', 'FI', 'DK', 'DE', 'FR', \n",
    "    'IT', 'ES', 'PL', 'RO', 'NL', 'BE'\n",
    "]\n",
    "\n",
    "# Label Mapping (for visualization tool tooltips/axis)\n",
    "COUNTRY_LABELS = {\n",
    "    'EU27_2020': 'EU Average', \n",
    "    'SE': 'Sweden', 'FI': 'Finland', 'DK': 'Denmark', \n",
    "    'DE': 'Germany', 'FR': 'France', 'IT': 'Italy', \n",
    "    'ES': 'Spain', 'PL': 'Poland', 'RO': 'Romania', \n",
    "    'NL': 'Netherlands', 'BE': 'Belgium'\n",
    "}\n",
    "\n",
    "def get_input_file():\n",
    "    for f in INPUT_FILES:\n",
    "        if os.path.exists(f):\n",
    "            return f\n",
    "    return None\n",
    "\n",
    "def process_race_to_zero():\n",
    "    input_path = get_input_file()\n",
    "    \n",
    "    if not input_path:\n",
    "        print(f\"Error: Input file not found. Checked: {INPUT_FILES}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"Analyzing renewable growth ({START_YEAR}-{END_YEAR}) from {input_path}...\")\n",
    "\n",
    "    try:\n",
    "        # 1. Load Data\n",
    "        with gzip.open(input_path, 'rt') as f:\n",
    "            df = pd.read_csv(f, sep='\\t', dtype=str)\n",
    "\n",
    "        # 2. Parse Metadata\n",
    "        first_col = df.columns[0]\n",
    "        meta = df[first_col].str.split(',', expand=True)\n",
    "        \n",
    "        df['nrg_bal'] = meta[1]\n",
    "        df['geo'] = meta[3].str.split(r'\\\\').str[0].str.strip()\n",
    "        df.drop(columns=[first_col], inplace=True)\n",
    "\n",
    "        # 3. Filter Data\n",
    "        # Keep only 'REN' (Total Renewables) and selected countries\n",
    "        mask = (df['nrg_bal'] == 'REN') & (df['geo'].isin(SELECTED_COUNTRIES))\n",
    "        df = df[mask].copy()\n",
    "\n",
    "        # 4. Melt (Wide to Long)\n",
    "        id_vars = ['nrg_bal', 'geo']\n",
    "        value_vars = [c for c in df.columns if c not in id_vars and c.strip().isdigit()]\n",
    "        \n",
    "        df_melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='Year', value_name='Value')\n",
    "\n",
    "        # 5. Clean Values (Vectorized)\n",
    "        # Remove flags, convert to numeric\n",
    "        df_melted['Value'] = df_melted['Value'].astype(str).str.split().str[0]\n",
    "        df_melted['Value'] = pd.to_numeric(df_melted['Value'], errors='coerce')\n",
    "        \n",
    "        # Clean Year\n",
    "        df_melted['Year'] = df_melted['Year'].astype(int)\n",
    "\n",
    "        # 6. Filter for Start and End Years\n",
    "        df_final = df_melted[df_melted['Year'].isin([START_YEAR, END_YEAR])].copy()\n",
    "        \n",
    "        # 7. Pivot for Slope Chart format\n",
    "        # Structure: Country | Value_Start | Value_End\n",
    "        df_pivot = df_final.pivot(index='geo', columns='Year', values='Value').reset_index()\n",
    "        \n",
    "        # Rename columns dynamically based on config\n",
    "        df_pivot.rename(columns={START_YEAR: f'Value_{START_YEAR}', END_YEAR: f'Value_{END_YEAR}'}, inplace=True)\n",
    "        \n",
    "        # 8. Enrich Data\n",
    "        # Calculate absolute growth (percentage points)\n",
    "        start_col = f'Value_{START_YEAR}'\n",
    "        end_col = f'Value_{END_YEAR}'\n",
    "        \n",
    "        df_pivot['Growth_Points'] = df_pivot[end_col] - df_pivot[start_col]\n",
    "        \n",
    "        # Map nice names\n",
    "        df_pivot['Country_Name'] = df_pivot['geo'].map(COUNTRY_LABELS).fillna(df_pivot['geo'])\n",
    "        \n",
    "        # Sort by growth\n",
    "        df_pivot = df_pivot.sort_values('Growth_Points', ascending=False)\n",
    "        \n",
    "        # Reorder columns for clean export\n",
    "        cols = ['Country_Name', start_col, end_col, 'Growth_Points']\n",
    "        df_pivot = df_pivot[cols]\n",
    "\n",
    "        # 9. Export\n",
    "        df_pivot.to_csv(OUTPUT_FILE, index=False)\n",
    "        \n",
    "        print(f\"Success. Comparison data exported to {OUTPUT_FILE}\")\n",
    "        print(df_pivot.head(10))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_race_to_zero()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progetto_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
